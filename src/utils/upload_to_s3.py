import boto3
import os
from pathlib import Path
from dotenv import load_dotenv
from botocore.exceptions import NoCredentialsError, ClientError

# ==========================================
# 1. LOAD CREDENTIALS (DEBUG MODE)
# ==========================================
# We explicitly tell Python: "Look for .env in the current folder"
load_dotenv()

print("üîç DEBUG: Checking credentials...")
access_key = os.getenv("AWS_ACCESS_KEY_ID")
secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")

if not access_key:
    print("‚ùå ERROR: .env file was found, but AWS_ACCESS_KEY_ID is empty.")
    print("üëâ Check your .env file. It should look like: AWS_ACCESS_KEY_ID=AKIA...")
    print("üëâ Make sure you SAVED the .env file (Ctrl+S).")
    exit(1)
elif " " in access_key:
    print("‚ùå ERROR: Your Access Key has spaces in it!")
    print("üëâ Remove any spaces around the '=' sign in your .env file.")
    exit(1)
else:
    print(f"‚úÖ Credentials loaded! Key starts with: {access_key[:4]}...")

# ==========================================
# 2. CONFIGURATION
# ==========================================
BUCKET_NAME = "housing-project-moosa-2025"  # Ensure this is unique
REGION = "eu-west-2"
PROJECT_ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = PROJECT_ROOT / "data" / "processed"

def create_bucket_if_not_exists(s3_client, bucket_name, region=None):
    try:
        s3_client.head_bucket(Bucket=bucket_name)
        print(f"‚úÖ Bucket '{bucket_name}' already exists.")
    except ClientError:
        print(f"‚ö†Ô∏è Bucket '{bucket_name}' not found. Creating it...")
        try:
            if region is None:
                s3_client.create_bucket(Bucket=bucket_name)
            else:
                location = {'LocationConstraint': region}
                s3_client.create_bucket(Bucket=bucket_name, CreateBucketConfiguration=location)
            print(f"‚úÖ Created bucket '{bucket_name}' successfully.")
        except ClientError as e:
            print(f"‚ùå Failed to create bucket: {e}")
            exit(1)

def upload_files(s3_client, bucket_name, local_path):
    if not local_path.exists():
        print(f"‚ùå Data directory not found: {local_path}")
        return

    print(f"\nüöÄ Starting upload from {local_path}...")
    files_uploaded = 0
    for root, dirs, files in os.walk(local_path):
        for file in files:
            local_file_path = Path(root) / file
            s3_key = f"data/processed/{file}"
            try:
                s3_client.upload_file(str(local_file_path), bucket_name, s3_key)
                print(f"   üì§ Uploaded {file}")
                files_uploaded += 1
            except Exception as e:
                print(f"‚ùå Error uploading {file}: {e}")

    if files_uploaded > 0:
        print(f"\n‚úÖ Success! Uploaded {files_uploaded} files to S3.")
    else:
        print("\n‚ö†Ô∏è No files were uploaded.")

if __name__ == "__main__":
    s3 = boto3.client('s3', region_name=REGION)
    create_bucket_if_not_exists(s3, BUCKET_NAME, REGION)
    upload_files(s3, BUCKET_NAME, DATA_DIR)